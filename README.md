<p align="center">
  <img src="frontend/public/logo.png" alt="Xendrix Logo" width="180"/>
</p>

<h1 align="center">Xendrix AI Assistant</h1>

<p align="center">
  <strong>An intelligent, multimodal AI assistant with chat, RAG, visualization, and image generation.</strong>
</p>

<p align="center">
  <a href="#"><img src="https://img.shields.io/badge/Python-3.9%2B-blue.svg"/></a>
  <a href="#"><img src="https://img.shields.io/badge/FastAPI-Backend-green.svg"/></a>
  <a href="#"><img src="https://img.shields.io/badge/Next.js-Frontend-black.svg"/></a>
  <a href="#"><img src="https://img.shields.io/badge/AI-Multimodal-purple.svg"/></a>
  <a href="LICENSE"><img src="https://img.shields.io/badge/License-MIT-yellow.svg"/></a>
  <a href="#"><img src="https://img.shields.io/badge/Status-Active-success.svg"/></a>
</p>

---

## ğŸ“Œ Overview

**Xendrix** is a **multimodal AI assistant** combining conversational AI, Retrieval-Augmented Generation (RAG), multilingual understanding, data visualization, mathematical reasoning, and image generation.

It uses a **FastAPI backend** and a **Next.js frontend**, making it suitable for **research, productivity tools, and real-world AI assistant deployments**.

---

## âœ¨ Key Features

- ğŸ’¬ Conversational chat with **persistent chat history**
- ğŸŒ Multilingual support  
  *(English, Hindi, Tamil, Telugu, French, Spanish, German, Japanese, Chinese, Russian, Arabic, Portuguese)*
- ğŸ§  Introduction & name detection across languages
- ğŸ“„ File upload + **Retrieval-Augmented Generation (RAG)**
  - Supported formats: `.pdf`, `.docx`, `.csv`
  - Chunking, embeddings (`all-MiniLM-L6-v2`), FAISS indexing
- ğŸ“Š Data visualization
  - Backend-rendered charts (Matplotlib)
  - Frontend interactive charts (Recharts)
- ğŸ¨ Image generation using **Stable Diffusion v1.5** (CPU / CUDA)
- â— Math problem solving using **SymPy** with KaTeX rendering
- ğŸ’» Code highlighting (Prism.js) + typing animation
- ğŸŒ¦ï¸ Utility integrations
  - Weather queries (Weatherstack)
  - Web search (SerpAPI with key rotation)
  - Translations (Deep Translator)

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Framework**: FastAPI (Python)
- **Core Libraries**:
  - sentence-transformers
  - FAISS
  - matplotlib
  - sympy
  - pandas
  - PyPDF2
  - python-docx
- **Models / Engines**:
  - Embeddings: `all-MiniLM-L6-v2`
  - Image Generation: Stable Diffusion v1.5
  - Chat Models: Ollama-hosted models (Mistral / Gemma â€“ configurable)
- **Storage**:
  - JSON (chat history)
  - Pickle
  - FAISS vector store

### Frontend
- **Framework**: Next.js (React)
- **Visualization**: Recharts
- **Rendering**: Prism.js, KaTeX

### Other
- SerpAPI
- Weatherstack
- Deep Translator
- Optional Docker workflow

---

## ğŸ“‚ Project Structure

```text
XendrixAI/
â”œâ”€â”€ frontend/                 # Next.js frontend (UI, chat, visualizations)
â”œâ”€â”€ backend/                  # FastAPI backend (AI logic, RAG, image gen)
â”œâ”€â”€ chats.json                # Persistent chat history (auto-generated)
â”œâ”€â”€ vector_db/                # FAISS indices & metadata (runtime)
â”œâ”€â”€ examples/                 # Sample inputs (if present)
â”œâ”€â”€ LICENSE                   # MIT License
â””â”€â”€ README.md                 # Project documentation
````

---

## ğŸš€ Installation (Development)

### Prerequisites

* Python **3.9+**
* Node.js **16+**
* npm or pnpm
* *(Optional)* CUDA-enabled GPU for faster image generation

---

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Kishore-1803/XendrixAI.git
cd XendrixAI
```

---

### 2ï¸âƒ£ Backend Setup

```bash
cd backend
python -m venv .venv

# macOS / Linux
source .venv/bin/activate

# Windows
.venv\Scripts\activate

pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Frontend Setup

```bash
cd ../frontend
npm install
npm run dev
# or: pnpm install && pnpm dev
```

---

## âš™ï¸ Configuration (Environment Variables)

Create a `.env` file or export variables:

```env
SERPAPI_KEY=your_serpapi_key
WEATHERSTACK_KEY=your_weatherstack_key
OLLAMA_HOST=http://localhost:11434
VECTOR_DB_DIR=vector_db
CHAT_HISTORY_FILE=chats.json
```

Backend constants such as `CHUNK_SIZE`, `TOP_K_RESULTS`, etc., can be adjusted in `backend/app.py`.

---

## â–¶ï¸ Running the Application

### Backend

```bash
cd backend
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

### Frontend

```bash
cd frontend
npm run dev
```

ğŸ“ Frontend: [http://localhost:3000](http://localhost:3000)
ğŸ“ Backend API: [http://localhost:8000](http://localhost:8000)

---

## ğŸ”Œ Important Backend Endpoints

* `GET  /chats` â€” List chat histories
* `POST /new_chat` â€” Create a new chat session
* `GET  /documents` â€” List uploaded documents
* `POST /upload_file` â€” Upload files for RAG
* `GET  /languages` â€” Supported languages
* Additional endpoints for image generation, visualization, and search

Refer to `backend/app.py` for full details.

---

## ğŸ“„ File Upload & RAG Pipeline

1. File ingestion (`.pdf`, `.docx`, `.csv`)
2. Text extraction and chunking
3. Embedding generation (`SentenceTransformers`)
4. FAISS indexing
5. Context retrieval at query time

---

## ğŸ¨ Image Generation

* Uses **Stable Diffusion v1.5**
* Automatically switches to **GPU** if CUDA is available
* CPU fallback supported (slower)

---

## ğŸ“Š Data Visualization

* Backend generates Matplotlib plots
* Frontend renders interactive charts via Recharts

---

## ğŸ§ª Development Notes

Recommended tooling:

* Python: `black`, `flake8`, `isort`, `pytest`
* Frontend: `eslint`, `prettier`

---

## ğŸ› ï¸ Troubleshooting

* Ensure backend runs on port **8000**
* Enable CORS for `http://localhost:3000`
* Large PDFs may require higher memory
* Keep `.env` files out of version control

---

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork the repository
2. Create a feature branch

   ```bash
   git checkout -b feat/your-feature
   ```
3. Commit changes and open a Pull Request

---

## ğŸ“„ License

This project is licensed under the **MIT License**.
See the [LICENSE](LICENSE) file for details.

---

â­ **If you like this project, consider starring the repository!** â­

Just tell me ğŸš€
```
